import math
import time
import re
from datetime import datetime, date, timedelta

import requests
import pandas as pd
import streamlit as st
import plotly.express as px

# -------------------------
# ì„¤ì •
# -------------------------
NAVER_NEWS_URL = "https://openapi.naver.com/v1/search/news.json"

st.set_page_config(page_title="ì–¸ì–´ì™€ ë§¤ì²´: ê¸°ì‚¬ ë¶„ì„ ë„êµ¬", layout="wide")
st.title("ğŸ“° ì–¸ì–´ì™€ ë§¤ì²´ ìˆ˜í–‰í‰ê°€: ê¸°ì‚¬ ìˆ˜ì§‘ Â· ë¶„ì„ (Naver News API)")

# -------------------------
# ìœ í‹¸
# -------------------------
def normalize_keywords(raw: str) -> list[str]:
    parts = re.split(r"[,\n;]+", raw)
    cleaned = []
    for p in parts:
        k = p.strip()
        if len(k) >= 2:
            cleaned.append(k)

    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    seen = set()
    out = []
    for k in cleaned:
        if k not in seen:
            out.append(k)
            seen.add(k)
    return out


def clean_html(text: str) -> str:
    return re.sub(r"<[^>]+>", "", text or "")


def safe_text(s: str) -> str:
    """HTMLì— ë„£ì–´ë„ ê¹¨ì§€ì§€ ì•Šê²Œ ìµœì†Œí•œì˜ escape"""
    if s is None:
        return ""
    return (
        str(s)
        .replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
    )


def parse_pubdate_to_dt(pub_raw: str):
    """
    ë„¤ì´ë²„ pubDate ì˜ˆ: 'Mon, 02 Feb 2026 11:04:00 +0900'
    datetime.strptimeë¡œ ì²˜ë¦¬
    """
    try:
        return datetime.strptime(pub_raw, "%a, %d %b %Y %H:%M:%S %z")
    except Exception:
        return None


def naver_api_headers():
    try:
        cid = st.secrets["NAVER_CLIENT_ID"]
        csec = st.secrets["NAVER_CLIENT_SECRET"]
    except Exception:
        st.error("Secretsì— NAVER_CLIENT_ID / NAVER_CLIENT_SECRET ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    return {
        "X-Naver-Client-Id": cid,
        "X-Naver-Client-Secret": csec,
    }


def dedup_articles(df: pd.DataFrame) -> pd.DataFrame:
    if df.empty:
        return df
    if "link" in df.columns:
        df = df.drop_duplicates(subset=["link"])
    if {"title", "pubDate"}.issubset(df.columns):
        df = df.drop_duplicates(subset=["title", "pubDate"])
    return df.reset_index(drop=True)


@st.cache_data(ttl=900, show_spinner=False)
def fetch_news_one_keyword(keyword: str, start_d: date, end_d: date, target_n: int, per_page: int = 100) -> pd.DataFrame:
    """
    ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ APIë¡œ ê¸°ì‚¬ ëª©ë¡ ìˆ˜ì§‘.
    - display ìµœëŒ€ 100 (per_page)
    - start 1ë¶€í„° í˜ì´ì§€ë„¤ì´ì…˜
    - ê¸°ê°„ì€ pubDateë¥¼ íŒŒì‹±í•´ì„œ ì•±ì—ì„œ í•„í„°ë§
    """
    headers = naver_api_headers()
    rows = []

    start = 1
    safety_pages = 0
    max_start = 1000  # ì•ˆì „ì¥ì¹˜

    while True:
        params = {
            "query": keyword,
            "display": per_page,
            "start": start,
            "sort": "date",
        }
        r = requests.get(NAVER_NEWS_URL, headers=headers, params=params, timeout=20)
        if r.status_code != 200:
            raise RuntimeError(f"ë„¤ì´ë²„ API ì˜¤ë¥˜: {r.status_code} / {r.text}")

        data = r.json()
        items = data.get("items", [])
        if not items:
            break

        for it in items:
            pub_raw = it.get("pubDate", "")
            pub_dt = parse_pubdate_to_dt(pub_raw)
            if pub_dt is None:
                continue

            # ê¸°ê°„ í•„í„°(ë¡œì»¬ ë‚ ì§œ ê¸°ì¤€)
            pub_local_date = pub_dt.astimezone().date()
            if not (start_d <= pub_local_date <= end_d):
                continue

            rows.append({
                "keyword": keyword,
                "pubDate": pub_dt.astimezone().strftime("%Y-%m-%d %H:%M"),
                "title": clean_html(it.get("title", "")),
                "description": clean_html(it.get("description", "")),
                "link": it.get("link", ""),
                "originallink": it.get("originallink", ""),
            })

        if len(rows) >= target_n:
            break

        start += per_page
        safety_pages += 1
        if start > max_start:
            break
        if safety_pages >= 12:  # ë¬´í•œë£¨í”„ ë°©ì§€
            break

        time.sleep(0.2)

    return pd.DataFrame(rows)


def build_report_html(df: pd.DataFrame, evidence: dict, start_d: date, end_d: date) -> str:
    """
    ë³´ê³ ì„œ HTML ìƒì„± (ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ í•©ì¹˜ê¸° ë°©ì‹)
    """
    # ê·¼ê±° 2ë¬¸ì¥ ìˆëŠ” ê²ƒë§Œ
    valid_items = [(k, v) for k, v in evidence.items() if v.get("e1") and v.get("e2")]

    # í‘œ rows
    trs = []
    for idx, v in valid_items:
        frames = ", ".join(v.get("frame", []))
        tr = (
            "<tr>"
            f"<td>{idx}</td>"
            f"<td>{safe_text(v.get('pubDate',''))}</td>"
            f"<td>{safe_text(v.get('keyword',''))}</td>"
            f"<td>{safe_text(v.get('title',''))}</td>"
            f"<td>{safe_text(frames)}</td>"
            f"<td>{safe_text(v.get('level',''))}</td>"
            f"<td>{safe_text(v.get('e1',''))}</td>"
            f"<td>{safe_text(v.get('e2',''))}</td>"
            f"<td><a href=\"{safe_text(v.get('link',''))}\" target=\"_blank\">link</a></td>"
            "</tr>"
        )
        trs.append(tr)

    rows_html = "\n".join(trs)

    # í˜ì´ì§€ ë©”íƒ€
    created = datetime.now().strftime("%Y-%m-%d %H:%M")
    kws = ", ".join(sorted(set(df["keyword"].tolist()))) if not df.empty else ""
    n_articles = len(df)

    # CSSì˜ ì¤‘ê´„í˜¸ ë•Œë¬¸ì— f-stringì„ ì“°ì§€ ì•Šê³  ë‹¨ìˆœ ë¬¸ìì—´ë¡œ ì¡°ë¦½
    html = (
        "<!doctype html>"
        "<html><head><meta charset='utf-8'/>"
        "<title>ì–¸ì–´ì™€ ë§¤ì²´ ìˆ˜í–‰í‰ê°€ ë³´ê³ ì„œ</title>"
        "<style>"
        "body{font-family:Arial, sans-serif; line-height:1.4; padding:18px;}"
        "table{border-collapse:collapse; width:100%;}"
        "th,td{border:1px solid #ccc; padding:8px; vertical-align:top;}"
        "th{background:#f2f2f2;}"
        "h1{margin-bottom:6px;}"
        ".meta{color:#555; margin:8px 0 16px 0;}"
        ".note{margin-top:14px; color:#333;}"
        "</style>"
        "</head><body>"
        "<h1>ì–¸ì–´ì™€ ë§¤ì²´ ìˆ˜í–‰í‰ê°€ ë³´ê³ ì„œ</h1>"
        f"<div class='meta'>"
        f"ìƒì„± ì‹œê°: {created}<br/>"
        f"ì…ë ¥ í‚¤ì›Œë“œ: {safe_text(kws)}<br/>"
        f"ê¸°ì‚¬ ìˆ˜ì§‘ ê¸°ê°„: {start_d} ~ {end_d}<br/>"
        f"ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜: {n_articles}"
        f"</div>"
        "<h2>Claimâ€“Evidenceâ€“Source í‘œ</h2>"
        "<p>â€» ê° í•­ëª©ì€ í•™ìƒì´ ì…ë ¥í•œ â€˜ê·¼ê±° ë¬¸ì¥â€™ì„ ê¸°ë°˜ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤.</p>"
        "<table>"
        "<thead><tr>"
        "<th>No</th><th>ë‚ ì§œ</th><th>í‚¤ì›Œë“œ</th><th>ê¸°ì‚¬ ì œëª©</th>"
        "<th>í”„ë ˆì„</th><th>ê·¼ê±° ìˆ˜ì¤€</th><th>ê·¼ê±° ë¬¸ì¥ 1</th><th>ê·¼ê±° ë¬¸ì¥ 2</th><th>ì¶œì²˜</th>"
        "</tr></thead>"
        "<tbody>"
        f"{rows_html}"
        "</tbody>"
        "</table>"
        "<div class='note'><b>PDF ì €ì¥:</b> ì´ HTMLì„ ì—´ê³  ë¸Œë¼ìš°ì € ì¸ì‡„(Ctrl+P) â†’ â€˜PDFë¡œ ì €ì¥â€™</div>"
        "</body></html>"
    )
    return html


# -------------------------
# ì‚¬ì´ë“œë°” ì…ë ¥
# -------------------------
with st.sidebar:
    st.header("ê²€ìƒ‰ ì¡°ê±´")

    start_d, end_d = st.date_input(
        "ê¸°ê°„ ì„¤ì •",
        value=(date.today() - timedelta(days=30), date.today()),
    )

    raw_keywords = st.text_area(
        "í‚¤ì›Œë“œ ì—¬ëŸ¬ ê°œ ì…ë ¥ (ì‰¼í‘œ/ì¤„ë°”ê¿ˆ ê°€ëŠ¥)",
        value="ì €ì¶œì‚°, ì¶œìƒë¥ , ì¸êµ¬ì ˆë²½",
        height=120,
    )

    target_total = st.number_input("ëª©í‘œ ê¸°ì‚¬ ìˆ˜ (ìµœì†Œ 50)", min_value=50, value=60, step=10)
    per_keyword_cap = st.number_input("í‚¤ì›Œë“œë‹¹ ìµœëŒ€ ìˆ˜ì§‘ ëª©í‘œ(ì•ˆì „ì¥ì¹˜)", min_value=30, value=120, step=10)

    run = st.button("ìˆ˜ì§‘ ì‹œì‘", type="primary")


# -------------------------
# ì‹¤í–‰
# -------------------------
if run:
    keywords = normalize_keywords(raw_keywords)
    if not keywords:
        st.warning("í‚¤ì›Œë“œë¥¼ 1ê°œ ì´ìƒ ì…ë ¥í•˜ì„¸ìš”. (ì˜ˆ: ì €ì¶œì‚°, ì¶œìƒë¥ )")
        st.stop()

    st.info(f"í‚¤ì›Œë“œ {len(keywords)}ê°œ: {', '.join(keywords)}")

    per_need = math.ceil(target_total / len(keywords))
    per_need = min(per_need, int(per_keyword_cap))

    frames = []
    with st.spinner("ê¸°ì‚¬ ìˆ˜ì§‘ ì¤‘..."):
        for kw in keywords:
            try:
                df_kw = fetch_news_one_keyword(kw, start_d, end_d, per_need)
                frames.append(df_kw)
            except Exception as e:
                st.error(f"'{kw}' ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

    df = pd.concat(frames, ignore_index=True) if frames else pd.DataFrame()
    if df.empty:
        st.error("ìˆ˜ì§‘ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤. ê¸°ê°„/í‚¤ì›Œë“œë¥¼ ë°”ê¿”ë³´ì„¸ìš”.")
        st.stop()

    df = dedup_articles(df)

    # ë¶€ì¡±í•˜ë©´ ì²« í‚¤ì›Œë“œë¡œ ì¶”ê°€ ìˆ˜ì§‘í•´ì„œ ì±„ìš°ê¸°
    if len(df) < target_total:
        st.warning(f"í˜„ì¬ {len(df)}ê°œë§Œ ìˆ˜ì§‘ë¨ â†’ ì¶”ê°€ ìˆ˜ì§‘ ì‹œë„")
        remain = target_total - len(df)
        extra = fetch_news_one_keyword(keywords[0], start_d, end_d, remain + 30)
        df = pd.concat([df, extra], ignore_index=True)
        df = dedup_articles(df)

    st.success(f"ìµœì¢… ìˆ˜ì§‘: {len(df)}ê°œ (ëª©í‘œ {target_total})")
    # âœ… rerunë¼ë„ ë°ì´í„° ìœ ì§€(í•µì‹¬)
    st.session_state["df"] = df
    st.session_state["start_d"] = start_d
    st.session_state["end_d"] = end_d
    st.session_state["data_ready"] = True

    
    # -------------------------
    # íƒ­ UI (â‘ ~â‘£)
    # -------------------------
    tabs = st.tabs(["â‘  ê¸°ì‚¬ ëª©ë¡", "â‘¡ í†µê³„ ëŒ€ì‹œë³´ë“œ", "â‘¢ ê·¼ê±° ì…ë ¥", "â‘£ ë³´ê³ ì„œ"])

    with tabs[0]:
        st.subheader("â‘  ê¸°ì‚¬ ëª©ë¡")
        st.dataframe(df[["pubDate", "keyword", "title", "link"]], use_container_width=True)
        st.download_button(
            "CSV ë‹¤ìš´ë¡œë“œ(ê¸°ì‚¬ ëª©ë¡)",
            data=df.to_csv(index=False).encode("utf-8-sig"),
            file_name="articles.csv",
            mime="text/csv",
        )

    with tabs[1]:
        st.subheader("â‘¡ í†µê³„ ëŒ€ì‹œë³´ë“œ")

        df["date"] = df["pubDate"].str.slice(0, 10)

        by_date = df.groupby("date")["title"].count().reset_index(name="count")
        fig1 = px.line(by_date, x="date", y="count", markers=True, title="ë‚ ì§œë³„ ê¸°ì‚¬ëŸ‰")
        st.plotly_chart(fig1, use_container_width=True)

        by_kw = (
            df.groupby("keyword")["title"]
            .count()
            .reset_index(name="count")
            .sort_values("count", ascending=False)
        )
        fig2 = px.bar(by_kw, x="keyword", y="count", title="í‚¤ì›Œë“œë³„ ê¸°ì‚¬ëŸ‰")
        st.plotly_chart(fig2, use_container_width=True)

        st.subheader("â‘¢ ì œëª© ê°•ì¡°ì–´ ë¹ˆë„(ê°„ë‹¨)")
        hype_words = ["ì¶©ê²©", "ë…¼ë€", "íŒŒì¥", "ê¸´ê¸‰", "í­ë¡œ", "ì¶©ëŒ", "ê²½ì•…", "ë¹„ìƒ", "ì „ê²©"]
        hype_df = pd.DataFrame({
            "word": hype_words,
            "count": [int(df["title"].str.contains(w).sum()) for w in hype_words]
        }).sort_values("count", ascending=False)

        fig3 = px.bar(hype_df, x="word", y="count", title="ê°•ì¡°/ì„ ì • í‘œí˜„ ë¹ˆë„(ì œëª© ê¸°ì¤€)")
        st.plotly_chart(fig3, use_container_width=True)

    with tabs[2]:
        st.subheader("â‘¢ ê·¼ê±° ì…ë ¥")
        st.write("ê¸°ì‚¬ë³„ë¡œ **ê·¼ê±° ë¬¸ì¥ 2ê°œ** + **í”„ë ˆì„**ì„ ì…ë ¥í•˜ê³  ì €ì¥í•˜ì„¸ìš”. (ì´ê²Œ ìˆì–´ì•¼ ë³´ê³ ì„œ ìƒì„± ê°€ëŠ¥)")

        if "evidence" not in st.session_state:
            st.session_state.evidence = {}

        idx = st.number_input("ê¸°ì‚¬ ë²ˆí˜¸ ì„ íƒ(0ë¶€í„°)", min_value=0, max_value=len(df)-1, value=0, step=1)
        row = df.iloc[int(idx)]

        st.markdown(f"**ì œëª©:** {row['title']}")
        st.markdown(f"**í‚¤ì›Œë“œ:** {row.get('keyword','')}")
        st.markdown(f"**ë‚ ì§œ:** {row.get('pubDate','')}")
        st.markdown(f"**ë§í¬:** {row.get('link','')}")

        saved = st.session_state.evidence.get(int(idx), {})
        e1 = st.text_area("ê·¼ê±° ë¬¸ì¥ 1(ê¸°ì‚¬ì—ì„œ ê·¸ëŒ€ë¡œ ë³µì‚¬)", value=saved.get("e1", ""), height=80)
        e2 = st.text_area("ê·¼ê±° ë¬¸ì¥ 2(ê¸°ì‚¬ì—ì„œ ê·¸ëŒ€ë¡œ ë³µì‚¬)", value=saved.get("e2", ""), height=80)

        frame = st.multiselect(
            "í”„ë ˆì„(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
            ["ê°ˆë“±/ëŒ€ë¦½", "ì±…ì„ ê·€ì¸", "ê²½ì œ/ë¹„ìš©", "ë„ë•/ê°€ì¹˜", "ê³µí¬/ìœ„í—˜", "í•´ê²°/ì •ì±…", "ì¸ë¬¼ ì¤‘ì‹¬", "ë°ì´í„°/ì—°êµ¬ ì¤‘ì‹¬"],
            default=saved.get("frame", [])
        )

        levels = ["ë°ì´í„°/ë³´ê³ ì„œ ëª…ì‹œ", "ì‹¤ëª… ì „ë¬¸ê°€/ê¸°ê´€ ì¸ìš©", "ë‹¹ì‚¬ì ì¸í„°ë·°", "ìµëª… ê´€ê³„ì", "ì¶”ì •/ê°€ëŠ¥ì„± í‘œí˜„ ìœ„ì£¼"]
        level_saved = saved.get("level", levels[0])
        level_index = levels.index(level_saved) if level_saved in levels else 0

        evidence_level = st.selectbox("ê·¼ê±° ìˆ˜ì¤€", levels, index=level_index)

        if st.button("ì´ ê¸°ì‚¬ ì…ë ¥ ì €ì¥", type="primary"):
            st.session_state.evidence[int(idx)] = {
                "e1": e1.strip(),
                "e2": e2.strip(),
                "frame": frame,
                "level": evidence_level,
                "title": row.get("title", ""),
                "link": row.get("link", ""),
                "pubDate": row.get("pubDate", ""),
                "keyword": row.get("keyword", ""),
            }
            st.success("ì €ì¥ ì™„ë£Œ!")

        st.divider()
        ev = st.session_state.evidence
        valid = [k for k, v in ev.items() if v.get("e1") and v.get("e2")]
        st.info(f"ê·¼ê±° 2ë¬¸ì¥ ì…ë ¥ ì™„ë£Œ: {len(valid)}ê°œ ê¸°ì‚¬")

    with tabs[3]:
        st.subheader("â‘£ ë³´ê³ ì„œ")

        ev = st.session_state.get("evidence", {})
        valid_items = [(k, v) for k, v in ev.items() if v.get("e1") and v.get("e2")]

        min_required = 3
        st.write(f"ê·¼ê±° ì…ë ¥ ì™„ë£Œ ê¸°ì‚¬ ìˆ˜: **{len(valid_items)}ê°œ** / í•„ìš”: **{min_required}ê°œ**")

        if len(valid_items) < min_required:
            st.warning("â‘¢ ê·¼ê±° ì…ë ¥ì—ì„œ ìµœì†Œ 3ê°œ ê¸°ì‚¬ì— ê·¼ê±° ë¬¸ì¥ 2ê°œë¥¼ ì…ë ¥í•˜ê³  ì €ì¥í•˜ì„¸ìš”.")
            st.stop()

        html = build_report_html(df, ev, start_d, end_d)

        st.download_button(
            "HTML ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
            data=html.encode("utf-8"),
            file_name="report.html",
            mime="text/html",
        )
        st.info("PDFëŠ” report.htmlì„ ì—´ê³  ë¸Œë¼ìš°ì € ì¸ì‡„(Ctrl+P) â†’ â€˜PDFë¡œ ì €ì¥â€™ì´ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.")
# âœ… ìˆ˜ì§‘ ë²„íŠ¼ì„ ëˆ„ë¥´ì§€ ì•Šì•„ë„, session_stateì— dfê°€ ìˆìœ¼ë©´ ê³„ì† ë³´ì—¬ì£¼ê¸°
if st.session_state.get("data_ready") and "df" in st.session_state:
    df = st.session_state["df"]
    start_d = st.session_state["start_d"]
    end_d = st.session_state["end_d"]

    # -------------------------
    # íƒ­ UI (â‘ ~â‘£)  â† ê¸°ì¡´ íƒ­ ì½”ë“œ í†µì§¸ë¡œ ì—¬ê¸°ë¡œ ì˜®ê²¨ë„ ë˜ê³ ,
    # ì´ë¯¸ if run ì•ˆì— ìˆë‹¤ë©´ "ê·¸ ë¶€ë¶„ì„ ì˜ë¼ì„œ" ì—¬ê¸°ë¡œ ë¶™ì—¬ë„£ìœ¼ë©´ ê°€ì¥ ê¹”ë”í•©ë‹ˆë‹¤.
    # -------------------------
    tabs = st.tabs(["â‘  ê¸°ì‚¬ ëª©ë¡", "â‘¡ í†µê³„ ëŒ€ì‹œë³´ë“œ", "â‘¢ ê·¼ê±° ì…ë ¥", "â‘£ ë³´ê³ ì„œ"])

    with tabs[0]:
        st.subheader("â‘  ê¸°ì‚¬ ëª©ë¡")
        st.dataframe(df[["pubDate", "keyword", "title", "link"]], use_container_width=True)
        st.download_button(
            "CSV ë‹¤ìš´ë¡œë“œ(ê¸°ì‚¬ ëª©ë¡)",
            data=df.to_csv(index=False).encode("utf-8-sig"),
            file_name="articles.csv",
            mime="text/csv",
        )

    with tabs[1]:
        st.subheader("â‘¡ í†µê³„ ëŒ€ì‹œë³´ë“œ")
        df["date"] = df["pubDate"].str.slice(0, 10)
        by_date = df.groupby("date")["title"].count().reset_index(name="count")
        st.plotly_chart(px.line(by_date, x="date", y="count", markers=True, title="ë‚ ì§œë³„ ê¸°ì‚¬ëŸ‰"), use_container_width=True)

        by_kw = df.groupby("keyword")["title"].count().reset_index(name="count").sort_values("count", ascending=False)
        st.plotly_chart(px.bar(by_kw, x="keyword", y="count", title="í‚¤ì›Œë“œë³„ ê¸°ì‚¬ëŸ‰"), use_container_width=True)

    with tabs[2]:
        st.subheader("â‘¢ ê·¼ê±° ì…ë ¥")

        if "evidence" not in st.session_state:
            st.session_state.evidence = {}

        idx = st.number_input("ê¸°ì‚¬ ë²ˆí˜¸ ì„ íƒ(0ë¶€í„°)", min_value=0, max_value=len(df)-1, value=0, step=1)
        row = df.iloc[int(idx)]

        st.markdown(f"**ì œëª©:** {row['title']}")
        st.markdown(f"**í‚¤ì›Œë“œ:** {row.get('keyword','')}")
        st.markdown(f"**ë‚ ì§œ:** {row.get('pubDate','')}")
        st.markdown(f"**ë§í¬:** {row.get('link','')}")

        saved = st.session_state.evidence.get(int(idx), {})
        e1 = st.text_area("ê·¼ê±° ë¬¸ì¥ 1(ê¸°ì‚¬ì—ì„œ ê·¸ëŒ€ë¡œ ë³µì‚¬)", value=saved.get("e1", ""), height=80)
        e2 = st.text_area("ê·¼ê±° ë¬¸ì¥ 2(ê¸°ì‚¬ì—ì„œ ê·¸ëŒ€ë¡œ ë³µì‚¬)", value=saved.get("e2", ""), height=80)

        frame = st.multiselect(
            "í”„ë ˆì„(ë³µìˆ˜ ì„ íƒ ê°€ëŠ¥)",
            ["ê°ˆë“±/ëŒ€ë¦½", "ì±…ì„ ê·€ì¸", "ê²½ì œ/ë¹„ìš©", "ë„ë•/ê°€ì¹˜", "ê³µí¬/ìœ„í—˜", "í•´ê²°/ì •ì±…", "ì¸ë¬¼ ì¤‘ì‹¬", "ë°ì´í„°/ì—°êµ¬ ì¤‘ì‹¬"],
            default=saved.get("frame", [])
        )

        levels = ["ë°ì´í„°/ë³´ê³ ì„œ ëª…ì‹œ", "ì‹¤ëª… ì „ë¬¸ê°€/ê¸°ê´€ ì¸ìš©", "ë‹¹ì‚¬ì ì¸í„°ë·°", "ìµëª… ê´€ê³„ì", "ì¶”ì •/ê°€ëŠ¥ì„± í‘œí˜„ ìœ„ì£¼"]
        level_saved = saved.get("level", levels[0])
        level_index = levels.index(level_saved) if level_saved in levels else 0
        evidence_level = st.selectbox("ê·¼ê±° ìˆ˜ì¤€", levels, index=level_index)

        if st.button("ì´ ê¸°ì‚¬ ì…ë ¥ ì €ì¥", type="primary"):
            st.session_state.evidence[int(idx)] = {
                "e1": e1.strip(),
                "e2": e2.strip(),
                "frame": frame,
                "level": evidence_level,
                "title": row.get("title", ""),
                "link": row.get("link", ""),
                "pubDate": row.get("pubDate", ""),
                "keyword": row.get("keyword", ""),
            }
            st.success("ì €ì¥ ì™„ë£Œ!")

        valid = [k for k, v in st.session_state.evidence.items() if v.get("e1") and v.get("e2")]
        st.info(f"ê·¼ê±° 2ë¬¸ì¥ ì…ë ¥ ì™„ë£Œ: {len(valid)}ê°œ ê¸°ì‚¬")

    with tabs[3]:
        st.subheader("â‘£ ë³´ê³ ì„œ")
        ev = st.session_state.get("evidence", {})
        valid_items = [(k, v) for k, v in ev.items() if v.get("e1") and v.get("e2")]

        min_required = 3
        st.write(f"ê·¼ê±° ì…ë ¥ ì™„ë£Œ ê¸°ì‚¬ ìˆ˜: **{len(valid_items)}ê°œ** / í•„ìš”: **{min_required}ê°œ**")

        if len(valid_items) < min_required:
            st.warning("â‘¢ ê·¼ê±° ì…ë ¥ì—ì„œ ìµœì†Œ 3ê°œ ê¸°ì‚¬ì— ê·¼ê±° ë¬¸ì¥ 2ê°œë¥¼ ì…ë ¥í•˜ê³  ì €ì¥í•˜ì„¸ìš”.")
        else:
            html = build_report_html(df, ev, start_d, end_d)
            st.download_button(
                "HTML ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
                data=html.encode("utf-8"),
                file_name="report.html",
                mime="text/html",
            )
            st.info("PDFëŠ” report.htmlì„ ì—´ê³  ë¸Œë¼ìš°ì € ì¸ì‡„(Ctrl+P) â†’ â€˜PDFë¡œ ì €ì¥â€™ì´ ê°€ì¥ ì•ˆì •ì ì…ë‹ˆë‹¤.")
else:
    st.caption("ì™¼ìª½ì—ì„œ ê¸°ê°„/í‚¤ì›Œë“œ ì…ë ¥ â†’ â€˜ìˆ˜ì§‘ ì‹œì‘â€™ì„ ëˆ„ë¥´ì„¸ìš”.")

